{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide & Deep Recommendation System with Movie Lens\n",
    "출처 : [Microsoft Github] (https://github.com/microsoft/recommenders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:31:29.863954 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:167: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CPUs:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import papermill as pm\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "from python_splitters import python_random_split\n",
    "import wide_deep_utils as wide_deep\n",
    "import tf_utils\n",
    "from pandas_df_utils import user_item_pairs\n",
    "import python_evaluation\n",
    "\n",
    "print(\"Tensorflow Version:\", tf.VERSION)\n",
    "devices = device_lib.list_local_devices()\n",
    "print([x.name for x in devices])\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "print(\"Num CPUs:\", num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# 파라미터 세팅\n",
    "####################\n",
    "#Recommend top k items\n",
    "TOP_K = 10\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "# Metrics to use for evaluation. reco_utils.evaluation.python_evaluation function names\n",
    "RANKING_METRICS = ['map_at_k', 'ndcg_at_k', 'precision_at_k', 'recall_at_k']\n",
    "RATING_METRICS = ['rmse', 'mae', 'rsquared', 'exp_var']\n",
    "# Use session hook to evaluate model while training\n",
    "EVALUATE_WHILE_TRAINING = True\n",
    "\n",
    "# Data column names\n",
    "USER_COL = 'UserId'\n",
    "ITEM_COL = 'MovieId'\n",
    "RATING_COL = 'Rating'\n",
    "ITEM_FEAT_COL = 'Genres'\n",
    "\n",
    "# Train and test set pickle file paths. If None, download and split the dataset.\n",
    "DATA_DIR = None\n",
    "TRAIN_PICKLE_PATH = None\n",
    "TEST_PICKLE_PATH = None\n",
    "EXPORT_DIR_BASE = './outputs/model'\n",
    "\n",
    "#### Hyperparameters\n",
    "MODEL_TYPE = 'wide_deep'\n",
    "EPOCHS = 50  # if 0, only 1 batch will be processed\n",
    "BATCH_SIZE = 64\n",
    "# Wide (linear) model hyperparameters\n",
    "LINEAR_OPTIMIZER = 'Ftrl'\n",
    "LINEAR_OPTIMIZER_LR =0.0029   # Learning rate\n",
    "LINEAR_L1_REG = 0.0           # L1 Regularization rate for FtrlOptimizer\n",
    "LINEAR_MOMENTUM = 0.9         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "# DNN model hyperparameters\n",
    "DNN_OPTIMIZER = 'Adagrad'\n",
    "DNN_OPTIMIZER_LR = 0.1\n",
    "DNN_L1_REG = 0.0           # L1 Regularization rate for FtrlOptimizer\n",
    "DNN_MOMENTUM = 0.9         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "# Layer dimensions are defined separately to make this work with AzureML Hyperdrive\n",
    "DNN_HIDDEN_LAYER_1 = 0     # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_2 = 128   # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_3 = 256   # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_4 = 32    # With this setting, DNN hidden units will be = [512, 256, 128, 128]\n",
    "DNN_USER_DIM = 4\n",
    "DNN_ITEM_DIM = 4\n",
    "DNN_DROPOUT = 0.4\n",
    "DNN_BATCH_NORM = 1         # 1 to use batch normalization, 0 if not.\n",
    "\n",
    "# Set cache directory path if want to keep the model checkpoints\n",
    "MODEL_DIR = './cahce/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserId  MovieId  Rating   timestamp         MovieName  \\\n0       1        1     4.0   964982703  Toy Story (1995)   \n1       5        1     4.0   847434962  Toy Story (1995)   \n2       7        1     4.5  1106635946  Toy Story (1995)   \n3      15        1     2.5  1510577970  Toy Story (1995)   \n4      17        1     4.5  1305696483  Toy Story (1995)   \n\n                                 Genres_string  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1  Adventure|Animation|Children|Comedy|Fantasy  \n2  Adventure|Animation|Children|Comedy|Fantasy  \n3  Adventure|Animation|Children|Comedy|Fantasy  \n4  Adventure|Animation|Children|Comedy|Fantasy  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(no genres listed)' 'Action' 'Adventure' 'Animation' 'Children' 'Comedy'\n 'Crime' 'Documentary' 'Drama' 'Fantasy' 'Film-Noir' 'Horror' 'IMAX'\n 'Musical' 'Mystery' 'Romance' 'Sci-Fi' 'Thriller' 'War' 'Western']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MovieId                                Genres_string  \\\n0          1  Adventure|Animation|Children|Comedy|Fantasy   \n215        3                               Comedy|Romance   \n267        6                        Action|Crime|Thriller   \n369       47                             Mystery|Thriller   \n572       50                       Crime|Mystery|Thriller   \n\n                                                Genres  \n0    [0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n215  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n267  [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n369  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n572  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# 데이터 전처리\n",
    "# 1. Rating Data & Genres Data\n",
    "###############################\n",
    "df_rating = pd.read_csv('./data/100K_Latest/ratings.csv', \n",
    "                        sep=\",\", skiprows=1, header=None, \n",
    "                        names=[USER_COL, ITEM_COL, RATING_COL, 'timestamp'], engine='python')\n",
    "df_movie = pd.read_csv('./data/100K_Latest/movies.csv', \n",
    "                       sep=\",\", skiprows=1, header=None, \n",
    "                       names=[ITEM_COL, 'MovieName', 'Genres_string'], engine='python')\n",
    "\n",
    "# print('df_ratings \\n', df_rating.head())\n",
    "# print('df_movie \\n', df_movie.head())\n",
    "\n",
    "df_data = pd.merge(df_rating, df_movie)\n",
    "\n",
    "print('df_data \\n', df_data.head())\n",
    "\n",
    "\n",
    "###############################\n",
    "# 데이터 전처리\n",
    "# 2. Feature 인코딩\n",
    "###############################\n",
    "# Encode 'genres' into int array (multi-hot representation) to use as item features\n",
    "genres_encoder = sklearn.preprocessing.MultiLabelBinarizer()\n",
    "df_data[ITEM_FEAT_COL] = genres_encoder.fit_transform(\n",
    "    df_data['Genres_string'].apply(lambda s: s.split(\"|\"))\n",
    ").tolist()\n",
    "print(\"Genres:\", genres_encoder.classes_)\n",
    "print(df_data.drop_duplicates(ITEM_COL)[[ITEM_COL, 'Genres_string', ITEM_FEAT_COL]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = 75627, test = 25209"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# Train, Test 데이터 나누기\n",
    "###############################\n",
    "train, test = python_random_split(\n",
    "    df_data.drop('Genres_string', axis=1),  # We don't need Genres original string column\n",
    "    ratio=0.75,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Train = {}, test = {}\".format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num items = 9724, num users = 610"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# item, user 수 확인\n",
    "###############################\n",
    "# Unique items in the dataset\n",
    "if ITEM_FEAT_COL is None:\n",
    "    items = df_data.drop_duplicates(ITEM_COL)[[ITEM_COL]].reset_index(drop=True)\n",
    "    item_feat_shape = None\n",
    "else:\n",
    "    items = df_data.drop_duplicates(ITEM_COL)[[ITEM_COL, ITEM_FEAT_COL]].reset_index(drop=True)\n",
    "    item_feat_shape = len(items[ITEM_FEAT_COL][0])\n",
    "# Unique users in the dataset\n",
    "users = df_data.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n",
    "\n",
    "print(\"Num items = {}, num users = {}\".format(len(items), len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN hidden units ="
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 256, 32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 610 users to 4-dim vector"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 9724 items to 4-dim vector"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# 최소 한 번은 학습 & 체크포인트 저장하도록 세팅\n",
    "##############################################\n",
    "train_steps = max(1, EPOCHS * len(train) // BATCH_SIZE)\n",
    "save_checkpoints_steps = max(1, train_steps // 5)\n",
    "\n",
    "##########################################################\n",
    "# MODEL_DIR 에 모델이 존재하면 존재하는 모델을 학습을 이어서\n",
    "# 모델의 구조가 다르면 에러 발생\n",
    "##########################################################\n",
    "if MODEL_DIR is None:\n",
    "    tmp_dir = TemporaryDirectory()\n",
    "    MODEL_DIR = tmp_dir.name\n",
    "\n",
    "\n",
    "############\n",
    "# 모델 세팅\n",
    "############\n",
    "DNN_HIDDEN_UNITS = [DNN_HIDDEN_LAYER_1, DNN_HIDDEN_LAYER_2, DNN_HIDDEN_LAYER_3, DNN_HIDDEN_LAYER_4]\n",
    "DNN_HIDDEN_UNITS = [h for h in DNN_HIDDEN_UNITS if h > 0] \n",
    "if MODEL_TYPE is 'deep' or MODEL_TYPE is 'wide_deep':\n",
    "    print(\"DNN hidden units =\", DNN_HIDDEN_UNITS)\n",
    "    print(\"Embedding {} users to {}-dim vector\".format(len(users), DNN_USER_DIM))\n",
    "    print(\"Embedding {} items to {}-dim vector\".format(len(items), DNN_ITEM_DIM))\n",
    "\n",
    "##########################\n",
    "# 옵티마이저 파라미터 세팅\n",
    "##########################\n",
    "linear_params = {}\n",
    "if LINEAR_OPTIMIZER == 'Ftrl':\n",
    "    linear_params['l1_regularization_strength'] = LINEAR_L1_REG\n",
    "elif LINEAR_OPTIMIZER == 'Momentum' or LINEAR_OPTIMIZER == 'RMSProp':\n",
    "    linear_params['momentum'] = LINEAR_MOMENTUM\n",
    "\n",
    "dnn_params = {}\n",
    "if DNN_OPTIMIZER == 'Ftrl':\n",
    "    dnn_params['l1_regularization_strength'] = DNN_L1_REG\n",
    "elif DNN_OPTIMIZER == 'Momentum' or DNN_OPTIMIZER == 'RMSProp':\n",
    "    dnn_params['momentum'] = DNN_MOMENTUM\n",
    "\n",
    "print(\"\\n\", linear_params, dnn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nFeature specs:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossedColumn(keys=(VocabularyListCategoricalColumn(key='UserId', vocabulary_list=(1, 5, 7, 15, 17, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='UserId', vocabulary_list=(1,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='MovieId', vocabulary_list=(1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumericColumn(key='Genres', shape=(20,), default_value=None, dtype=tf.float32, normalizer_fn=None)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# Model Feature 세팅 - wide(linear) & deep(dnn)\n",
    "################################################\n",
    "wide_columns, deep_columns = wide_deep.build_feature_columns(\n",
    "    users=users[USER_COL].values,\n",
    "    items=items[ITEM_COL].values,\n",
    "    user_col=USER_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    item_feat_col=ITEM_FEAT_COL,\n",
    "    user_dim=DNN_USER_DIM,\n",
    "    item_dim=DNN_ITEM_DIM,\n",
    "    item_feat_shape=item_feat_shape,\n",
    "    model_type=MODEL_TYPE,\n",
    ")\n",
    "\n",
    "print(\"\\nFeature specs:\")\n",
    "for c in wide_columns + deep_columns:\n",
    "    print(str(c)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:32:15.039165 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:82: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:32:15.052129 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:78: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# 세팅한 파라미터에 기반한 모델 빌드\n",
    "####################################\n",
    "model = wide_deep.build_model(\n",
    "    model_dir=MODEL_DIR,\n",
    "    wide_columns=wide_columns,\n",
    "    deep_columns=deep_columns,\n",
    "    linear_optimizer=tf_utils.build_optimizer(LINEAR_OPTIMIZER, LINEAR_OPTIMIZER_LR, **linear_params),\n",
    "    dnn_optimizer=tf_utils.build_optimizer(DNN_OPTIMIZER, DNN_OPTIMIZER_LR, **dnn_params),\n",
    "    dnn_hidden_units=DNN_HIDDEN_UNITS,\n",
    "    dnn_dropout=DNN_DROPOUT,\n",
    "    dnn_batch_norm=(DNN_BATCH_NORM==1),\n",
    "    log_every_n_iter=max(1, train_steps//20),  # log 20 times\n",
    "    save_checkpoints_steps=save_checkpoints_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = {\n",
    "    'col_user': USER_COL,\n",
    "    'col_item': ITEM_COL,\n",
    "    'col_rating': RATING_COL,\n",
    "    'col_prediction': 'prediction'\n",
    "}\n",
    "\n",
    "#####################################\n",
    "# user와 item의 전체 조합(cross join)\n",
    "#####################################\n",
    "ranking_pool = user_item_pairs(\n",
    "    user_df=users,\n",
    "    item_df=items,\n",
    "    user_col=USER_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    user_item_filter_df=train,  # Remove seen items\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:43:49.105174 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:52: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:43:49.108168 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:52: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define training hooks to track performance while training\n",
    "hooks = []\n",
    "if EVALUATE_WHILE_TRAINING:\n",
    "    evaluation_logger = tf_utils.MetricsLogger()\n",
    "    metrics = (m for m in (RANKING_METRICS, RATING_METRICS) if len(m) > 0)\n",
    "    for ms in metrics:\n",
    "        hooks.append(\n",
    "            tf_utils.evaluation_log_hook(\n",
    "                model,\n",
    "                logger=evaluation_logger,\n",
    "                true_df=test,\n",
    "                y_col=RATING_COL,\n",
    "                eval_df=ranking_pool if ms==RANKING_METRICS else test.drop(RATING_COL, axis=1),\n",
    "                every_n_iter=save_checkpoints_steps,\n",
    "                model_dir=MODEL_DIR,\n",
    "                eval_fns=[getattr(python_evaluation, m) for m in ms],\n",
    "                **({**cols, 'k': TOP_K} if ms==RANKING_METRICS else cols)\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Define training input (sample feeding) function\n",
    "train_fn = tf_utils.pandas_input_fn(\n",
    "    df=train,\n",
    "    y_col=RATING_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=None,  # None == run forever. We use steps=TRAIN_STEPS instead.\n",
    "    shuffle=True,\n",
    "    num_threads=num_cpus-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training steps = 59083, Batch size = 64 (num epochs = 50)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:36.589709 11028 deprecation.py:323] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:36.783190 11028 deprecation.py:323] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:36.791169 11028 deprecation.py:323] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:53:36.873950 11028 estimator.py:1145] Calling model_fn."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:36.904866 11028 deprecation.py:506] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:37.531191 11028 deprecation.py:323] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:3038: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\nInstructions for updating:\nThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:38.758909 11028 deprecation.py:323] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:41.139543 11028 deprecation.py:323] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:42.330362 11028 deprecation.py:506] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow\\python\\training\\adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:53:42.682455 11028 estimator.py:1147] Done calling model_fn."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:53:42.685410 11028 basic_session_run_hooks.py:541] Create CheckpointSaverHook."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:43.060409 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:199: The name tf.summary.FileWriterCache is deprecated. Please use tf.compat.v1.summary.FileWriterCache instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:43.063401 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:200: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:53:43.527197 11028 monitored_session.py:240] Graph was finalized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:53:45.195738 11028 session_manager.py:500] Running local_init_op."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:53:45.371228 11028 session_manager.py:502] Done running local_init_op."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:45.441043 11028 deprecation.py:323] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:53:46.668798 11028 basic_session_run_hooks.py:606] Saving checkpoints for 0 into ./cahce/model\\model.ckpt."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:47.128779 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:207: The name tf.train.SessionRunArgs is deprecated. Please use tf.estimator.SessionRunArgs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:53:49.433370 11028 basic_session_run_hooks.py:262] loss = 1053.0758, step = 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:53:53.524430 11028 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 915 vs previous value: 915. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:54:02.302960 11028 basic_session_run_hooks.py:692] global_step/sec: 231.634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:54:02.309948 11028 basic_session_run_hooks.py:260] loss = 67.35977, step = 2955 (12.882 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:54:02.453554 11028 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2967 vs previous value: 2967. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:54:18.555501 11028 basic_session_run_hooks.py:692] global_step/sec: 180.285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:54:18.562483 11028 basic_session_run_hooks.py:260] loss = 42.57393, step = 5909 (16.253 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:54:25.107981 11028 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 6409 vs previous value: 6409. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:54:31.978610 11028 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 6816 vs previous value: 6816. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:54:51.608684 11028 basic_session_run_hooks.py:692] global_step/sec: 89.3711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:54:51.612673 11028 basic_session_run_hooks.py:260] loss = 47.872826, step = 8863 (33.050 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:54:53.151566 11028 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 9008 vs previous value: 9008. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 19:55:13.660748 11028 basic_session_run_hooks.py:606] Saving checkpoints for 11816 into ./cahce/model\\model.ckpt."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:55:14.707947 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:218: The name tf.logging.get_verbosity is deprecated. Please use tf.compat.v1.logging.get_verbosity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:55:14.711937 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:219: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 19:55:14.717920 11028 deprecation_wrapper.py:119] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\tf_utils.py:219: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:00:20.586909 11028 basic_session_run_hooks.py:692] global_step/sec: 8.97934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:00:20.655721 11028 basic_session_run_hooks.py:260] loss = 56.186836, step = 11817 (329.043 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:00:34.333011 11028 basic_session_run_hooks.py:692] global_step/sec: 214.882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:00:34.336995 11028 basic_session_run_hooks.py:260] loss = 42.11669, step = 14771 (13.681 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:00:51.023379 11028 basic_session_run_hooks.py:692] global_step/sec: 176.988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:00:51.029362 11028 basic_session_run_hooks.py:260] loss = 28.052593, step = 17725 (16.691 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:01:05.064837 11028 basic_session_run_hooks.py:692] global_step/sec: 210.377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:01:05.068825 11028 basic_session_run_hooks.py:260] loss = 48.668915, step = 20679 (14.040 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:01:18.537811 11028 basic_session_run_hooks.py:606] Saving checkpoints for 23632 into ./cahce/model\\model.ckpt."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:06:11.505718 11028 basic_session_run_hooks.py:692] global_step/sec: 9.63971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:06:11.643172 11028 basic_session_run_hooks.py:260] loss = 38.190994, step = 23633 (306.569 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:06:23.621141 11028 basic_session_run_hooks.py:692] global_step/sec: 243.841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:06:23.624135 11028 basic_session_run_hooks.py:260] loss = 43.85072, step = 26587 (11.987 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:06:37.942849 11028 basic_session_run_hooks.py:692] global_step/sec: 206.246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:06:37.945841 11028 basic_session_run_hooks.py:260] loss = 52.082386, step = 29541 (14.322 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:06:56.915120 11028 basic_session_run_hooks.py:692] global_step/sec: 155.701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:06:56.918113 11028 basic_session_run_hooks.py:260] loss = 31.841549, step = 32495 (18.972 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:07:10.772070 11028 basic_session_run_hooks.py:606] Saving checkpoints for 35448 into ./cahce/model\\model.ckpt."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:03.702912 11028 basic_session_run_hooks.py:692] global_step/sec: 8.05373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:03.751780 11028 basic_session_run_hooks.py:260] loss = 49.31167, step = 35449 (366.834 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:17.851082 11028 basic_session_run_hooks.py:692] global_step/sec: 208.79"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:17.855072 11028 basic_session_run_hooks.py:260] loss = 29.02741, step = 38403 (14.103 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:34.842650 11028 basic_session_run_hooks.py:692] global_step/sec: 173.841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:34.845641 11028 basic_session_run_hooks.py:260] loss = 48.463264, step = 41357 (16.991 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:46.663045 11028 basic_session_run_hooks.py:692] global_step/sec: 249.907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:46.667034 11028 basic_session_run_hooks.py:260] loss = 32.53171, step = 44311 (11.820 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:13:58.764690 11028 basic_session_run_hooks.py:606] Saving checkpoints for 47264 into ./cahce/model\\model.ckpt."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:17:16.856030 11028 basic_session_run_hooks.py:692] global_step/sec: 14.0538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:17:16.927842 11028 basic_session_run_hooks.py:260] loss = 31.52892, step = 47265 (210.256 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:17:29.300757 11028 basic_session_run_hooks.py:692] global_step/sec: 237.389"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:17:29.302752 11028 basic_session_run_hooks.py:260] loss = 42.666824, step = 50219 (12.381 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:17:41.593886 11028 basic_session_run_hooks.py:692] global_step/sec: 240.277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:17:41.598873 11028 basic_session_run_hooks.py:260] loss = 42.538452, step = 53173 (12.296 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:17:53.435226 11028 basic_session_run_hooks.py:692] global_step/sec: 249.486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:17:53.444206 11028 basic_session_run_hooks.py:260] loss = 36.007195, step = 56127 (11.845 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:18:06.565119 11028 basic_session_run_hooks.py:606] Saving checkpoints for 59080 into ./cahce/model\\model.ckpt."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 20:18:06.781541 11028 deprecation.py:323] From D:\\01.Programming\\PycharmProjects\\Recommenders-movielens\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to delete files with this prefix."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:21:20.343625 11028 basic_session_run_hooks.py:692] global_step/sec: 14.2768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:21:20.459316 11028 basic_session_run_hooks.py:260] loss = 34.39142, step = 59081 (207.009 sec)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:21:20.478265 11028 basic_session_run_hooks.py:606] Saving checkpoints for 59083 into ./cahce/model\\model.ckpt."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:21:23.102496 11028 estimator.py:368] Loss for final step: 33.314835."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training steps = {}, Batch size = {} (num epochs = {})\".format(train_steps, BATCH_SIZE, EPOCHS))\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "#################\n",
    "# 모델 학습 시작\n",
    "#################\n",
    "try:\n",
    "    model.train(\n",
    "        input_fn=train_fn,\n",
    "        hooks=hooks,\n",
    "        steps=train_steps\n",
    "    )\n",
    "except tf.train.NanLossDuringTrainingError:\n",
    "    raise ValueError(\n",
    "        \"\"\"Training stopped with NanLossDuringTrainingError.\n",
    "        Try other optimizers, smaller batch size and/or smaller learning rate.\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'papermill' has no attribute 'record'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-24d23dbba14c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mEVALUATE_WHILE_TRAINING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluation_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'papermill' has no attribute 'record'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "if EVALUATE_WHILE_TRAINING:\n",
    "    for m, v in evaluation_logger.get_log().items():\n",
    "        pm.record(\"eval_{}\".format(m), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:26:32.792201 11028 estimator.py:1145] Calling model_fn."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:26:34.226369 11028 estimator.py:1147] Done calling model_fn."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:26:34.580422 11028 monitored_session.py:240] Graph was finalized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:26:34.590394 11028 saver.py:1280] Restoring parameters from ./cahce/model\\model.ckpt-59083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:26:34.756949 11028 session_manager.py:500] Running local_init_op."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:26:34.826763 11028 session_manager.py:502] Done running local_init_op."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_df ::: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       UserId  MovieId   timestamp  \\\n67037     551    34162  1504925858   \n42175     232    59421  1217541086   \n93850     288     8880  1095780696   \n6187      414     1080   961595418   \n12229     577     2406   945965771   \n7433      502     1206  1111757634   \n53802     137     6787  1204859228   \n65098      97     4025  1047481289   \n68041     490    88125  1324376714   \n11854     593     2291  1181008449   \n\n                                               MovieName  \\\n67037                            Wedding Crashers (2005)   \n42175                    What Happens in Vegas... (2008)   \n93850                                        Mask (1985)   \n6187                 Monty Python's Life of Brian (1979)   \n12229                         Romancing the Stone (1984)   \n7433                          Clockwork Orange, A (1971)   \n53802                     All the President's Men (1976)   \n65098                           Miss Congeniality (2000)   \n68041  Harry Potter and the Deathly Hallows: Part 2 (...   \n11854                         Edward Scissorhands (1990)   \n\n                                                  Genres  prediction  \n67037  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    3.717763  \n42175  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    3.195282  \n93850  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...    3.250296  \n6187   [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    3.895330  \n12229  [0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    3.740880  \n7433   [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...    3.921042  \n53802  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...    4.142208  \n65098  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...    4.038630  \n68041  [0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, ...    3.189037  \n11854  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...    3.596118  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8912505265425538, 'mae': 0.6752194901811193, 'rsquared': 0.26311857056258414, 'exp_var': 0.2633145675924853}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if len(RATING_METRICS) > 0:\n",
    "    predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=test)))\n",
    "    prediction_df = test.drop(RATING_COL, axis=1)\n",
    "    prediction_df['prediction'] = [p['predictions'][0] for p in predictions]    \n",
    "    \n",
    "    print(\"prediction_df ::: \\n\", prediction_df[:10])\n",
    "    \n",
    "    rating_results = {}\n",
    "    for m in RATING_METRICS:\n",
    "        fn = getattr(python_evaluation, m)\n",
    "        result = fn(test, prediction_df, **cols)\n",
    "        # pm.record(m, result)\n",
    "        rating_results[m] = result\n",
    "    print(rating_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:26:59.349225 11028 estimator.py:1145] Calling model_fn."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:27:00.054309 11028 estimator.py:1147] Done calling model_fn."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:27:00.285690 11028 monitored_session.py:240] Graph was finalized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:27:00.292671 11028 saver.py:1280] Restoring parameters from ./cahce/model\\model.ckpt-59083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:27:00.390410 11028 session_manager.py:500] Running local_init_op."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0722 20:27:00.431303 11028 session_manager.py:502] Done running local_init_op."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_df ::: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserId  MovieId                                             Genres  \\\n0     289     3087  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n1     233    54503  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2     289      121  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n3     476     6597  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4     352      223  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n5     245     7026  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6     169      898  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n7     387    79590  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n8     513     4928  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n9     450     6832  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n\n   prediction  \n0    2.782947  \n1    3.388410  \n2    3.898042  \n3    3.802190  \n4    4.146657  \n5    1.674149  \n6    4.720969  \n7    2.606355  \n8    4.018032  \n9    4.089769  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map_at_k': 1.0714668381013606e-06, 'ndcg_at_k': 0.0001804030871295739, 'precision_at_k': 0.0001639344262295082, 'recall_at_k': 3.2144005143040823e-06}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if len(RANKING_METRICS) > 0:\n",
    "    predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=ranking_pool)))\n",
    "    prediction_df = ranking_pool.copy()\n",
    "    prediction_df['prediction'] = [p['predictions'][0] for p in predictions]\n",
    "\n",
    "    print(\"prediction_df ::: \\n\", prediction_df[:10])\n",
    "    \n",
    "    ranking_results = {}\n",
    "    for m in RANKING_METRICS:\n",
    "        fn = getattr(python_evaluation, m)\n",
    "        result = fn(test, prediction_df, **{**cols, 'k': TOP_K})\n",
    "        # pm.record(m, result)\n",
    "        ranking_results[m] = result\n",
    "    print(ranking_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(EXPORT_DIR_BASE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to b'./outputs/model\\\\1563665171'\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "train_rcvr_fn = tf.contrib.estimator.build_supervised_input_receiver_fn_from_input_fn(\n",
    "    train_fn\n",
    ")\n",
    "eval_rcvr_fn = tf.contrib.estimator.build_supervised_input_receiver_fn_from_input_fn(\n",
    "    tf_utils.pandas_input_fn(df=test, y_col=RATING_COL)\n",
    ")\n",
    "serve_rcvr_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "    tf.feature_column.make_parse_example_spec(wide_columns+deep_columns)\n",
    ")\n",
    "rcvr_fn_map = {\n",
    "    tf.estimator.ModeKeys.TRAIN: train_rcvr_fn,\n",
    "    tf.estimator.ModeKeys.EVAL: eval_rcvr_fn,\n",
    "    tf.estimator.ModeKeys.PREDICT: serve_rcvr_fn\n",
    "}\n",
    "\n",
    "export_dir = tf.contrib.estimator.export_all_saved_models(\n",
    "    model,\n",
    "    export_dir_base=EXPORT_DIR_BASE,\n",
    "    input_receiver_fn_map=rcvr_fn_map\n",
    ")\n",
    "# pm.record('saved_model_dir', str(export_dir))\n",
    "print(\"Model exported to\", str(export_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_my_rating ::: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    UserId  MovieId  Rating    timestamp\n0      999        1     4.0  964982703.0\n1      999        2     4.0  964983148.0\n33     999       36     4.0  964997388.0\n44     999       48     3.0  965002283.0\n46     999       50     5.0  965003173.0\n65     999       73     4.0  965011628.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ::: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       UserId  MovieId  Rating   timestamp  \\\n67037     551    34162     4.0  1504925858   \n42175     232    59421     2.0  1217541086   \n93850     288     8880     4.0  1095780696   \n6187      414     1080     5.0   961595418   \n12229     577     2406     4.0   945965771   \n7433      502     1206     5.0  1111757634   \n53802     137     6787     4.0  1204859228   \n65098      97     4025     3.0  1047481289   \n68041     490    88125     3.5  1324376714   \n11854     593     2291     3.0  1181008449   \n87810     201     2262     3.0   939811032   \n60512     225     1970     4.0   949261430   \n57994     385      551     3.0   834691914   \n46319     228     3555     4.0  1363222643   \n61839     480     2396     4.5  1179177705   \n47446      21    70286     3.5  1441826981   \n40203     502     2300     5.0  1111757731   \n19310     100      222     4.0  1100184420   \n86670     560    84944     3.0  1469648956   \n11134     328     2078     3.5  1494210562   \n82955     387     1019     3.5  1094939717   \n63526     474     3396     3.0   978576200   \n804       361       70     2.0  1204046026   \n95917     288     2286     2.0   975692708   \n50205     274    27773     3.5  1171408960   \n12883     540     2571     4.0  1179108880   \n1572       16      260     3.0  1377476936   \n84473      89    68659     2.0  1520408893   \n4939      418      648     0.5  1461868227   \n21325     251     1225     5.0  1470677293   \n...       ...      ...     ...         ...   \n24164     449     3996     3.5  1053198925   \n76291     177     1431     2.0  1435536428   \n32004     181      437     2.0   845470813   \n32538     566      497     4.0   849006808   \n59471      53     1441     5.0  1237748056   \n29038     145      165     3.0   832105183   \n61131     391     2171     3.0  1030945301   \n65336      28     4344     1.0  1234516387   \n88725     140     4994     3.0  1028042869   \n48207      68   122922     3.0  1526947686   \n68986      41     2160     5.0  1459368424   \n44336     597     2100     4.0   941641110   \n54107      28     8641     3.0  1242290779   \n97104     334    30850     3.5  1260653585   \n78171     381    53894     5.0  1187320063   \n95052     586   101362     4.5  1529903321   \n42168      10    59333     2.5  1455357564   \n24289      24     4027     4.0  1458941850   \n35346     195     4306     3.0   994032742   \n61682     217     2374     3.0   955944922   \n31662     351      381     3.0  1325978096   \n43651      91     1370     3.0  1112713590   \n39471     331    34319     2.0  1537158344   \n93407     380     3682     2.0  1495475964   \n35549     489     4370     1.5  1332773878   \n76051     177   111921     5.0  1435720961   \n35045     428     3916     2.5  1111489023   \n14383     202     2959     5.0   975013040   \n46656     122     7438     5.0  1461561437   \n94558     305    51412     4.0  1460366268   \n\n                                               MovieName  \\\n67037                            Wedding Crashers (2005)   \n42175                    What Happens in Vegas... (2008)   \n93850                                        Mask (1985)   \n6187                 Monty Python's Life of Brian (1979)   \n12229                         Romancing the Stone (1984)   \n7433                          Clockwork Orange, A (1971)   \n53802                     All the President's Men (1976)   \n65098                           Miss Congeniality (2000)   \n68041  Harry Potter and the Deathly Hallows: Part 2 (...   \n11854                         Edward Scissorhands (1990)   \n87810                         About Last Night... (1986)   \n60512  Nightmare on Elm Street 3: Dream Warriors, A (...   \n57994             Nightmare Before Christmas, The (1993)   \n46319                                       U-571 (2000)   \n61839                         Shakespeare in Love (1998)   \n47446                                  District 9 (2009)   \n40203                              Producers, The (1968)   \n19310                           Circle of Friends (1995)   \n86670                                       Rango (2011)   \n11134                            Jungle Book, The (1967)   \n82955                20,000 Leagues Under the Sea (1954)   \n63526                           Muppet Movie, The (1979)   \n804                           From Dusk Till Dawn (1996)   \n95917         Fiendish Plot of Dr. Fu Manchu, The (1980)   \n50205                                     Old Boy (2003)   \n12883                                 Matrix, The (1999)   \n1572           Star Wars: Episode IV - A New Hope (1977)   \n84473                                     Fanboys (2009)   \n4939                          Mission: Impossible (1996)   \n21325                                     Amadeus (1984)   \n...                                                  ...   \n24164  Crouching Tiger, Hidden Dragon (Wo hu cang lon...   \n76291                         Beverly Hills Ninja (1997)   \n32004                         Cops and Robbersons (1994)   \n32538                      Much Ado About Nothing (1993)   \n59471                                Benny & Joon (1993)   \n29038                  Die Hard: With a Vengeance (1995)   \n61131                        Next Stop Wonderland (1998)   \n65336                                   Swordfish (2001)   \n88725                               Majestic, The (2001)   \n48207                              Doctor Strange (2016)   \n68986                             Rosemary's Baby (1968)   \n44336                                      Splash (1984)   \n54107       Anchorman: The Legend of Ron Burgundy (2004)   \n97104                     Merchant of Venice, The (2004)   \n78171                                       Sicko (2007)   \n95052                          Olympus Has Fallen (2013)   \n42168                               Made of Honor (2008)   \n24289                  O Brother, Where Art Thou? (2000)   \n35346                                       Shrek (2001)   \n61682                                     Gung Ho (1986)   \n31662                    When a Man Loves a Woman (1994)   \n43651                                  Die Hard 2 (1990)   \n39471                                 Island, The (2005)   \n93407                                Magnum Force (1973)   \n35549                A.I. Artificial Intelligence (2001)   \n76051                      The Fault in Our Stars (2014)   \n35045                         Remember the Titans (2000)   \n14383                                  Fight Club (1999)   \n46656                           Kill Bill: Vol. 2 (2004)   \n94558                                        Next (2007)   \n\n                                                  Genres  \n67037  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n42175  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n93850  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n6187   [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n12229  [0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n7433   [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n53802  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n65098  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n68041  [0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, ...  \n11854  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n87810  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n60512  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n57994  [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, ...  \n46319  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n61839  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n47446  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n40203  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n19310  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n86670  [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n11134  [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n82955  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n63526  [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n804    [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n95917  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n50205  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n12883  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1572   [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n84473  [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n4939   [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n21325  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n...                                                  ...  \n24164  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n76291  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n32004  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n32538  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n59471  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n29038  [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n61131  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n65336  [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n88725  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n48207  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n68986  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n44336  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n54107  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n97104  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n78171  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n95052  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n42168  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n24289  [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n35346  [0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n61682  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n31662  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n43651  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n39471  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n93407  [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n35549  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n76051  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n35045  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n14383  [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n46656  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n94558  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n\n[25209 rows x 6 columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_my_data \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\nColumns: [UserId, MovieId, Rating, timestamp, MovieName, Genres_string]\nIndex: []"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# 내가 매긴 평가를 바탕으로 추천\n",
    "# my_ratings.csv에 각 영화에 대한 평점 입력\n",
    "# UserId : 999\n",
    "###########################################\n",
    "# 데이터 불러오기\n",
    "df_my_rating = pd.read_csv('./data/100K_Latest/my_ratings.csv', \n",
    "                        sep=\",\", skiprows=1, header=None, \n",
    "                        names=[USER_COL, ITEM_COL, RATING_COL, 'timestamp', 'movieName'], engine='python')\n",
    "\n",
    "# movieNmae 컬럼 삭제\n",
    "del df_my_rating['movieName']\n",
    "# 평가하지 않은 영화 삭제\n",
    "df_my_rating = df_my_rating.dropna(axis=0)\n",
    "\n",
    "print(\"df_my_rating ::: \\n\", df_my_rating)\n",
    "print(\"test ::: \\n\", test)\n",
    "\n",
    "df_my_data = pd.merge(df_my_rating, df_data)\n",
    "\n",
    "# df_data\n",
    "\n",
    "print('df_my_data \\n', df_my_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
